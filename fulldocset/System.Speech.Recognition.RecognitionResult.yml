### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.RecognitionResult
  id: RecognitionResult
  children:
  - System.Speech.Recognition.RecognitionResult.Alternates
  - System.Speech.Recognition.RecognitionResult.Audio
  - System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  - System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  langs:
  - csharp
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
  type: Class
  summary: "Contiene informazioni dettagliate sull&quot;input riconosciuto da istanze di <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> o <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>."
  remarks: "Questa classe deriva da <xref:System.Speech.Recognition.RecognizedPhrase>e vengono fornite informazioni dettagliate sul riconoscimento vocale, inclusi i seguenti: - il <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A>riferimenti alle proprietà di <xref:System.Speech.Recognition.Grammar>che il riconoscimento utilizzata per identificare il riconoscimento vocale.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> </xref:System.Speech.Recognition.RecognizedPhrase>      -La <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A>proprietà contiene il testo normalizzato per la frase.</xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Per ulteriori informazioni sulla normalizzazione del testo, vedere <xref:System.Speech.Recognition.ReplacementText>.</xref:System.Speech.Recognition.ReplacementText>      -La <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A>le informazioni semantiche contenute nel risultato fa riferimento a proprietà.</xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> Le informazioni semantiche sono un dizionario di dati semantici associati e i nomi delle chiavi.      -La <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>proprietà contiene una raccolta di <xref:System.Speech.Recognition.RecognizedPhrase>gli oggetti che rappresentano altri interpretazioni candidato dell&quot;input audio.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Vedere <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>Per ulteriori informazioni.</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>      -La <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A>proprietà contiene una raccolta ordinata di <xref:System.Speech.Recognition.RecognizedWordUnit>riconosciuto di oggetti che rappresentano ogni parola nell&quot;input.</xref:System.Speech.Recognition.RecognizedWordUnit> </xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Ogni <xref:System.Speech.Recognition.RecognizedWordUnit>contiene informazioni di pronuncia per la corrispondente parola, formato lessicale e formato di visualizzazione.</xref:System.Speech.Recognition.RecognizedWordUnit>       Alcuni membri del <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, e <xref:System.Speech.Recognition.Grammar>classi possono generare un RecognitionResult.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Per ulteriori informazioni, vedere i metodi e gli eventi seguenti.      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>      -   The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class.</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.Grammar.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognizer></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine>       Per ulteriori informazioni sugli eventi di riconoscimento, vedere [mediante gli eventi di riconoscimento vocale](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."
  example:
  - "The following example shows a handler for the `SpeechRecognized` event of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> or <xref:System.Speech.Recognition.SpeechRecognizer> object, and some of the information about the associated RecognitionResult.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: >-
      [System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")]

      public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable
  inheritance:
  - System.Object
  - System.Speech.Recognition.RecognizedPhrase
  implements:
  - System.Runtime.Serialization.ISerializable
  inheritedMembers:
  - System.Speech.Recognition.RecognizedPhrase.Confidence
  - System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics
  - System.Speech.Recognition.RecognizedPhrase.Grammar
  - System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId
  - System.Speech.Recognition.RecognizedPhrase.Homophones
  - System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits
  - System.Speech.Recognition.RecognizedPhrase.Semantics
  - System.Speech.Recognition.RecognizedPhrase.Text
  - System.Speech.Recognition.RecognizedPhrase.Words
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  id: Alternates
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Ottiene la raccolta di corrispondenze possibili per l&quot;input per il riconoscimento vocale."
  remarks: "Le alternative di riconoscimento vengono ordinate in base ai valori di loro <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>proprietà.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Il valore di probabilità di una frase specifica indica la probabilità che la frase corrisponde all&quot;input. L&quot;espressione con il valore più elevato di confidenza è la frase che probabilmente corrisponde all&quot;input.       Ogni <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>valore deve essere valutato singolarmente e senza riferimento ai valori di probabilità di altre alternative.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Le proprietà che la <xref:System.Speech.Recognition.RecognitionResult>eredita da <xref:System.Speech.Recognition.RecognizedPhrase>forniscono informazioni dettagliate sulla frase con il punteggio di confidenza più elevato.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult>       È possibile utilizzare la raccolta di alternative è per la correzione degli errori automatizzata. Ad esempio, quando si progetta una finestra di dialogo di directory, un&quot;applicazione potrebbe richiedere all&quot;utente di controllare se l&quot;applicazione che contiene le informazioni corrette da un evento di riconoscimento, come nel &quot;che hai detto&quot;Anna&quot;?&quot; Se l&quot;utente è indicato &quot;no&quot;, quindi l&quot;applicazione potrebbe chiedere all&quot;utente eventuali alternative che aveva un sufficientemente elevato <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>punteggio.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>       Per ulteriori informazioni sul riconoscimento vocale e l&quot;utilizzo di alternative di riconoscimento, vedere [il riconoscimento vocale](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919) e [mediante gli eventi di riconoscimento vocale](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."
  example:
  - "The following example shows a handler for the `SpeechRecognized` event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase> Alternates { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
      description: "Raccolta di sola lettura delle alternative di riconoscimento."
  overload: System.Speech.Recognition.RecognitionResult.Alternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Audio
  id: Audio
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Ottiene l&quot;audio associato al risultato di riconoscimento."
  remarks: "Per ottenere una sezione dell&quot;audio associato a un intervallo specifico di parole nel risultato del riconoscimento, utilizzare il <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>metodo.</xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>"
  example:
  - "The following example shows a handler for the **SpeechRecognized** event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n      Console.WriteLine(\"Audio for result:\");  \n      Console.WriteLine(\"  Start time: \"+ e.Result.Audio.StartTime);  \n      Console.WriteLine(\"  Duration: \" + e.Result.Audio.Duration);  \n      Console.WriteLine(\"  Format: \" + e.Result.Audio.Format.EncodingFormat);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio Audio { get; }
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "L&quot;audio associato al risultato di riconoscimento o <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> se il riconoscimento generato il risultato da una chiamata al <xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;> </xref> o <xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;> </xref> metodi di un <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> o <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> istanza."
  overload: System.Speech.Recognition.RecognitionResult.Audio*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  id: GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Ottiene una sezione dell&quot;audio associato a un intervallo specifico di parole nel risultato del riconoscimento."
  remarks: "Per ottenere l&quot;audio completo associato al risultato di riconoscimento, utilizzare il <xref:System.Speech.Recognition.RecognitionResult.Audio%2A>proprietà.</xref:System.Speech.Recognition.RecognitionResult.Audio%2A>"
  example:
  - "The following example creates a grammar to accept name input and attaches to it a handler for the `SpeechRecognized` event. The grammar uses a wildcard for the name element of the phrase. The event handler uses the audio from the wildcard to create and play a greeting prompt.  \n  \n```c#  \n  \nprivate Grammar CreateNameInputGrammar()  \n{  \n  GrammarBuilder wildcardBuilder = new GrammarBuilder();  \n  wildcardBuilder.AppendWildcard();  \n  SemanticResultKey nameKey =  \n    new SemanticResultKey(\"Name\", wildcardBuilder);  \n  \n  GrammarBuilder nameBuilder =  \n    new GrammarBuilder(\"My name is\");  \n  nameBuilder.Append(nameKey);  \n  \n  Grammar nameGrammar = new Grammar(nameBuilder);  \n  nameGrammar.Name = \"Name input\";  \n  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler<SpeechRecognizedEventArgs>(  \n      NameInputHandler);  \n  \n  return nameGrammar;  \n}  \n  \n// Handle the SpeechRecognized event for the name grammar.  \nprivate void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  SemanticValue semantics = e.Result.Semantics;  \n  \n  if (semantics.ContainsKey(\"Name\"))  \n  {  \n    RecognizedAudio nameAudio =  \n      result.GetAudioForWordRange(  \n        result.Words[3], result.Words[result.Words.Count - 1]);  \n  \n    // Save the audio. Create a directory and file as necessary.  \n    FileInfo fi = new FileInfo(@\"C:\\temp\\temp.wav\");  \n    if (!fi.Directory.Exists)  \n    {  \n      fi.Directory.Create();  \n    }  \n    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  \n    nameAudio.WriteToWaveStream(stream);  \n    stream.Close();  \n  \n    // Greet the person using the saved audio.  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(\"Hello\");  \n    builder.AppendAudio(fi.FullName);  \n    synthesizer.Speak(builder);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);
    parameters:
    - id: firstWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "La prima parola nell&quot;intervallo."
    - id: lastWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "L&quot;ultima parola nell&quot;intervallo."
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "La sezione dell&quot;audio associato all&quot;intervallo di word."
  overload: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  exceptions:
  - type: System.NullReferenceException
    commentId: T:System.NullReferenceException
    description: "Il riconoscimento ha generato il risultato da una chiamata a <xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;> </xref> o <xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;> </xref> metodi di <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> oggetti."
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  id: System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  isEii: true
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Popola un <xref href=&quot;System.Runtime.Serialization.SerializationInfo&quot;> </xref> istanza con i dati necessari per serializzare l&quot;oggetto di destinazione."
  remarks: "Questo membro è un&quot;implementazione esplicita dell&quot;interfaccia di un membro. E può essere utilizzato solo quando il <xref:System.Speech.Recognition.RecognitionResult>esegue il cast dell&quot;istanza di un <xref:System.Runtime.Serialization.ISerializable>interfaccia.</xref:System.Runtime.Serialization.ISerializable> </xref:System.Speech.Recognition.RecognitionResult>"
  syntax:
    content: void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);
    parameters:
    - id: info
      type: System.Runtime.Serialization.SerializationInfo
      description: "Oggetto da popolare con i dati."
    - id: context
      type: System.Runtime.Serialization.StreamingContext
      description: "La destinazione per la serializzazione."
  overload: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Speech.Recognition.RecognizedPhrase
  isExternal: false
  name: System.Speech.Recognition.RecognizedPhrase
- uid: System.NullReferenceException
  isExternal: true
  name: System.NullReferenceException
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizedPhrase>
  nameWithType: ReadOnlyCollection<RecognizedPhrase>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizedPhrase
    name: RecognizedPhrase
    nameWithType: RecognizedPhrase
    fullName: RecognizedPhrase
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.RecognitionResult.Audio
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognizedAudio
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedAudio
  nameWithType: RecognizedAudio
  fullName: System.Speech.Recognition.RecognizedAudio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
- uid: System.Speech.Recognition.RecognizedWordUnit
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
- uid: System.Runtime.Serialization.SerializationInfo
  parent: System.Runtime.Serialization
  isExternal: false
  name: SerializationInfo
  nameWithType: SerializationInfo
  fullName: System.Runtime.Serialization.SerializationInfo
- uid: System.Runtime.Serialization.StreamingContext
  parent: System.Runtime.Serialization
  isExternal: true
  name: StreamingContext
  nameWithType: StreamingContext
  fullName: System.Runtime.Serialization.StreamingContext
- uid: System.Speech.Recognition.RecognitionResult.Alternates*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
- uid: System.Speech.Recognition.RecognitionResult.Audio*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange
  nameWithType: RecognitionResult.GetAudioForWordRange
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData
